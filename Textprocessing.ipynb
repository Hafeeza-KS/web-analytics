{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f66ecc5d-cff8-4ef2-b203-643ec365d505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Tokenization:\n",
      "['Natural Language Toolkit (NLTK) is one of the largest Python libraries \\nfor performing various Natural Language Processing tasks.', 'From rudimentary \\ntasks such as text pre-processing to tasks like vectorized representation \\nof text – NLTK’s API has covered everything.']\n",
      "\n",
      "Word Tokenization:\n",
      "['Natural', 'Language', 'Toolkit', '(', 'NLTK', ')', 'is', 'one', 'of', 'the', 'largest', 'Python', 'libraries', 'for', 'performing', 'various', 'Natural', 'Language', 'Processing', 'tasks', '.', 'From', 'rudimentary', 'tasks', 'such', 'as', 'text', 'pre-processing', 'to', 'tasks', 'like', 'vectorized', 'representation', 'of', 'text', '–', 'NLTK', '’', 's', 'API', 'has', 'covered', 'everything', '.']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "# Download necessary NLTK datasets (only required once)\n",
    "#nltk.download('punkt')\n",
    "\n",
    "text = \"\"\"Natural Language Toolkit (NLTK) is one of the largest Python libraries \n",
    "for performing various Natural Language Processing tasks. From rudimentary \n",
    "tasks such as text pre-processing to tasks like vectorized representation \n",
    "of text – NLTK’s API has covered everything.\"\"\"\n",
    "\n",
    "# Tokenizing into sentences\n",
    "sentences = sent_tokenize(text)\n",
    "print(\"Sentence Tokenization:\")\n",
    "print(sentences)\n",
    "\n",
    "# Tokenizing into words\n",
    "words = word_tokenize(text)\n",
    "print(\"\\nWord Tokenization:\")\n",
    "print(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d80202b3-b8b4-4332-b1eb-8a5ef9a5d818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural Language Toolkit ( NLTK ) works powerful Python library wide range tools Natural Language Processing ( NLP ) . fundamental tasks like text pre-processing advanced operations semantic reasoning , NLTK provides versatile API caters diverse needs language-related tasks .\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download required NLTK data\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "\n",
    "# Given text\n",
    "text = \"\"\"Natural Language Toolkit (NLTK) works as a powerful Python library \n",
    "that a wide range of tools for Natural Language Processing (NLP). \n",
    "From fundamental tasks like text pre-processing to more advanced operations \n",
    "such as semantic reasoning, NLTK provides a versatile API that caters to \n",
    "the diverse needs of language-related tasks.\"\"\"\n",
    "\n",
    "# Tokenizing the text\n",
    "words = word_tokenize(text)\n",
    "\n",
    "# Getting stop words for English\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Removing stop words\n",
    "filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "\n",
    "# Printing the result\n",
    "print(\" \".join(filtered_words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0e03653-bc00-4831-a38c-cee96de58c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural Language Processing NLP is a field of AI that focuses on enabling computers to understand interpret generate human language NLP includes tasks like tokenization lemmatization sentiment analysis It helps in applications such as chatbots machine translation and voice assistants However cleaning textremoving extra spaces punctuations special charactersis crucial Without preprocessing NLP models may not perform accurately So can you clean this messy text make it structured\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"\"\" @@Natural Language Processing (NLP)!!! is a field of AI that\n",
    "focuses on ...\n",
    "enabling computers to understand, interpret, & generate human\n",
    "language.\n",
    "NLP includes tasks like **tokenization, lemmatization,** &&\n",
    "sentiment analysis.\n",
    "It helps in applications such as chatbots, machine translation,\n",
    "and voice assistants!!!\n",
    "However, cleaning text—removing extra spaces, punctuations, &&\n",
    "special $$$ characters—is crucial.\n",
    "Without preprocessing, NLP models may not perform\n",
    "accurately !!!\n",
    "So, can you clean this messy text & make it structured??? \"\"\"\n",
    "\n",
    "# Remove special characters\n",
    "cleaned_text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)\n",
    "\n",
    "# Remove extra whitespaces\n",
    "cleaned_text = re.sub(r\"\\s+\", \" \", cleaned_text).strip()\n",
    "\n",
    "print(cleaned_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "882f1c2b-00c5-40da-938d-f502b299f338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lets eat grandma\n",
      "grandma lets eat\n",
      "silvia are you free tomorrow\n",
      "yes im free on saturday\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "# Given text\n",
    "text = \"\"\"Let’s eat, Grandma!\n",
    "Grandma, Let’s eat!\n",
    "Silvia, Are you free tomorrow?\n",
    "Yes, I’m free on Saturday.\"\"\"\n",
    "\n",
    "# Convert to lowercase\n",
    "text = text.lower()\n",
    "\n",
    "# Remove punctuation using regex\n",
    "text = re.sub(r\"[^\\w\\s]\", \"\", text)  # Removes all punctuation\n",
    "\n",
    "# Print the cleaned text\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32f6f0f9-014c-45a9-b95d-f533c542a833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmed Words: ['the', 'research', 'are', 'analyz', 'variou', 'dataset', 'to', 'studi', 'the', 'effect', 'of', 'autom', '.', 'they', 'observ', 'that', 'autom', 'system', 'perform', 'task', 'more', 'effici', 'than', 'human', '.', 'mani', 'industri', 'have', 'been', 'adopt', 'ai-driven', 'solut', 'to', 'improv', 'product', '.', 'run', 'complex', 'algorithm', 'help', 'in', 'predict', 'futur', 'trend', 'accur', '.', 'sever', 'compani', 'are', 'invest', 'in', 'develop', 'smarter', 'and', 'more', 'adapt', 'model', '.', 'data', 'scientist', 'continu', 'refin', 'their', 'model', 'to', 'achiev', 'better', 'perform', '.', 'the', 'advanc', 'in', 'technolog', 'have', 'transform', 'the', 'way', 'busi', 'oper', '.']\n",
      "\n",
      "Lemmatized Words: ['The', 'researcher', 'are', 'analyzing', 'various', 'datasets', 'to', 'study', 'the', 'effect', 'of', 'automation', '.', 'They', 'observed', 'that', 'automated', 'system', 'perform', 'task', 'more', 'efficiently', 'than', 'human', '.', 'Many', 'industry', 'have', 'been', 'adopting', 'AI-driven', 'solution', 'to', 'improve', 'productivity', '.', 'Running', 'complex', 'algorithm', 'help', 'in', 'predicting', 'future', 'trend', 'accurately', '.', 'Several', 'company', 'are', 'investing', 'in', 'developing', 'smarter', 'and', 'more', 'adaptive', 'model', '.', 'Data', 'scientist', 'continuously', 'refine', 'their', 'model', 'to', 'achieve', 'better', 'performance', '.', 'The', 'advancement', 'in', 'technology', 'have', 'transformed', 'the', 'way', 'business', 'operate', '.']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('omw-1.4')\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "text = \"\"\"The researchers are analyzing various datasets to study the effects \n",
    "of automation. They observed that automated systems perform tasks more \n",
    "efficiently than humans. Many industries have been adopting AI-driven \n",
    "solutions to improve productivity. Running complex algorithms helps in \n",
    "predicting future trends accurately. Several companies are investing in \n",
    "developing smarter and more adaptive models. Data scientists continuously \n",
    "refine their models to achieve better performance. The advancements in \n",
    "technology have transformed the way businesses operate.\"\"\"\n",
    "\n",
    "words = word_tokenize(text)\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "stemmed_words = [stemmer.stem(word) for word in words]\n",
    "lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "print(\"Stemmed Words:\", stemmed_words)\n",
    "print(\"\\nLemmatized Words:\", lemmatized_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4127b64-80a7-498f-9885-53b2b966db87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
